{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCf++QQm8MkRWQ12dSh1MK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nissimyo/DCGAN/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df29tDOEx5B-",
        "colab_type": "text"
      },
      "source": [
        "Before using, you need to verify you have versions:\n",
        "- TensorFlow: 2.3.0\n",
        "- Keras: 2.4.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gHeYtCGyZdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras as ke\n",
        "\n",
        "print(tf.__version__)\n",
        "print(ke.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jZqUWaIyhUV",
        "colab_type": "text"
      },
      "source": [
        "### If needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4bAqLuNk6SU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ2S3NIok_ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGeMnCbWUQE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from scipy.signal import hilbert\n",
        "\n",
        "import glob\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Conv1D, Flatten,Reshape,Conv1DTranspose\n",
        "from keras.layers.advanced_activations import LeakyReLU\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19-voV_sUgxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14193851-cba1-4d71-9e19-da1fb4edba03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-KDNfVLVBWL",
        "colab_type": "text"
      },
      "source": [
        "Reding file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhRaXsUAVBAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfs2_5 = pd.read_csv('/content/drive/My Drive/PHM DATA/XJTU/XJTU-SY_Bearing_Datasets/37.5Hz11kN/Bearing2_5/dfs2_5.csv')\n",
        "dfs2_5 = dfs2_5.drop(dfs2_5.columns[0], axis=1)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtF0g4YrUopD",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoHOqQliUDbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Signal_len = 4096\n",
        "\n",
        "def create_conv_discriminator(Signal_len = 4096, optimizer = 'adam'):\n",
        "\n",
        "  discriminator = Sequential()\n",
        "\n",
        "  discriminator.add(Reshape((Signal_len, 1), input_shape=(Signal_len,)))\n",
        "\n",
        "  discriminator.add(Conv1D(filters=32, kernel_size=25, activation='relu',input_shape=(Signal_len,1), strides=2))\n",
        "\n",
        "  discriminator.add(Conv1D(filters=64, kernel_size=25, activation='relu',strides=2))\n",
        "\n",
        "  discriminator.add(Conv1D(filters=128, kernel_size=25, activation='relu',strides=5))\n",
        "\n",
        "  discriminator.add(Conv1D(filters=256, kernel_size=25, activation='relu',strides=5))\n",
        "\n",
        "  discriminator.add(Flatten())\n",
        "\n",
        "  discriminator.add(Dense(256, activation = 'relu'))\n",
        "    \n",
        "  discriminator.add(Dense(1, activation='sigmoid')) #Does not appear in the paper\n",
        "\n",
        "  discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "  return discriminator\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M4NKDrRWi9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis = create_conv_discriminator()\n",
        "dis.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CttVJbuUsby",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIvAspuZUr4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Conv2DTranspose , Reshape,MaxPooling2D,MaxPooling1D,Flatten,Conv1DTranspose\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "noise_dim = 100\n",
        "def create_conv_generator(Signal_len = 4096, optimizer = 'adam'):\n",
        "\n",
        "  generator = Sequential()      \n",
        "\n",
        "  generator.add(Reshape((noise_dim, 1), input_shape=(noise_dim,)))\n",
        "\n",
        "  generator.add(keras.layers.Conv1DTranspose(filters=128,kernel_size=25,strides=4,input_shape=(noise_dim,1),activation='relu'))\n",
        "\n",
        "  generator.add(keras.layers.Conv1DTranspose(filters=64,kernel_size=25,strides=4,activation='relu'))\n",
        "\n",
        "  generator.add(keras.layers.Conv1DTranspose(filters=32,kernel_size=25,strides=4,activation='relu'))\n",
        "\n",
        "  generator.add(keras.layers.Conv1DTranspose(filters=1,kernel_size=25,strides=4,activation='tanh'))\n",
        "\n",
        "  generator.add(Flatten())\n",
        "\n",
        "  generator.add(Dense(4096)) #at the end?\n",
        "\n",
        "  generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "  return generator"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJvJFStfkEo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = create_conv_generator()\n",
        "gen.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNBdVBXfVMs5",
        "colab_type": "text"
      },
      "source": [
        "## Combine all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PaiwHaKU5Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "noise_dim = 100\n",
        "optimizer = 'adam'\n",
        "\n",
        "dis.trainable = False\n",
        "\n",
        "gan_input = Input(shape=(noise_dim,1,))\n",
        "fake_signal = gen(gan_input)\n",
        "\n",
        "gan_output = dis(fake_signal)\n",
        "\n",
        "gan = Model(gan_input, gan_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Babm19TkVtRb",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdMaK1woVp-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## change to seperated signals\n",
        "x_train = np.array(dfs2_5.iloc[0:180])\n",
        "x_train = x_train.reshape(180*8,np.int(32768/8)) # Splitting the signals to 4096"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xBWfkNaVwny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 10\n",
        "steps_per_epoch = 10\n",
        "\n",
        "##GAN - training with for loop\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(steps_per_epoch):\n",
        "        noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
        "        fake_x = gen.predict(noise)\n",
        "\n",
        "        real_x = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n",
        "        \n",
        "        x = np.concatenate((real_x, fake_x))\n",
        "\n",
        "        disc_y = np.zeros(2*batch_size)\n",
        "        disc_y[:batch_size] = 0.9\n",
        "\n",
        "        #dis.trainable=True\n",
        "        d_loss = dis.train_on_batch(x, disc_y)\n",
        "\n",
        "        y_gen = np.ones(batch_size)\n",
        "\n",
        "        #dis.trainable=False\n",
        "\n",
        "        g_loss = gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "    print(f'Epoch: {epoch} \\t Discriminator Loss: {d_loss} \\t\\t Generator Loss: {g_loss}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah3RglAxmPVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis.predict(x_train[180*8].reshape(1,4096))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz8mxgXmmXij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,13))\n",
        "pred = gen.predict(np.random.normal(0,1,100).reshape(-1,100))[0]\n",
        "plt.plot(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRjuO_E6mZ2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = np.int(4096) # Number of sample points\n",
        "T = 1.28/8\n",
        "dT = T/N # sample spacing\n",
        "#x = np.linspace(0.0, T-dT, N)\n",
        "\n",
        "yf = sp.fft.fft(np.array(gen.predict(np.random.normal(0,1,100).reshape(-1,100))[0]))\n",
        "xf = np.linspace(0.0, 1.0/(2.0*dT), N//2)\n",
        "f = px.line(x=xf, y=np.log(2.0/N * np.abs(yf[0:N//2])))\n",
        "f.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "349lsaory97H",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGyBAkW7r7K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## change to seperated signals\n",
        "x_test = np.array(dfs2_5.iloc[0:330])\n",
        "x_test = x_test.reshape(330*8,np.int(32768/8)) # Splitting the signals to 4096\n",
        "dis.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48geaNcdshhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis.predict(x_test[300*8].reshape(1,4096))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}